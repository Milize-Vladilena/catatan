<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-05-17">

<title>rantai markov waktu kontinu ‚Äì Catatan üìù</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-b53751a350365c71b6c909e95f209ed1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ddd961a2510921635943dfbbd19534c4.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-8aa8884591a9136173b71f6048871fae.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Catatan üìù</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#fungsi-probabilitas-transisi" id="toc-fungsi-probabilitas-transisi" class="nav-link active" data-scroll-target="#fungsi-probabilitas-transisi">6.4 Fungsi Probabilitas Transisi</a>
  <ul class="collapse">
  <li><a href="#proposition-6.1-1" id="toc-proposition-6.1-1" class="nav-link" data-scroll-target="#proposition-6.1-1">Proposition 6.1</a></li>
  <li><a href="#contoh-6.8" id="toc-contoh-6.8" class="nav-link" data-scroll-target="#contoh-6.8">Contoh 6.8</a></li>
  <li><a href="#contoh-6.9" id="toc-contoh-6.9" class="nav-link" data-scroll-target="#contoh-6.9">Contoh 6.9</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">rantai markov waktu kontinu</h1>
  <div class="quarto-categories">
    <div class="quarto-category">modstok</div>
    <div class="quarto-category">kuliah</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 17, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>Diskrit v.s. Kontinu</p>
<p>Waktu diskrit: Kejadian terjadi pada titik waktu yang diketahui.</p>
<p>Waktu kontinu: Kejadian terjadi pada titik sembarang waktu.</p>
<hr>
<p>Ruang keadaan kontinu ini tetap diskrit meskipun ruang parameter nya kontinu.</p>
<hr>
<div class="callout callout-style-default callout-note callout-titled" title="Bahasa Inggrisnya">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bahasa Inggrisnya
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="the-transition-probability-function-p_ijt" class="level2">
<h2 class="anchored" data-anchor-id="the-transition-probability-function-p_ijt">6.4 The Transition Probability Function <span class="math inline">\(P_{ij}(t)\)</span></h2>
<p>Let<br>
<span class="math display">\[P_{ij}(t) = \mathbb{P}\{X(t + s) = j \mid X(s) = i\}\]</span><br>
denote the probability that a process presently in state <span class="math inline">\(i\)</span> will be in state <span class="math inline">\(j\)</span> a time <span class="math inline">\(t\)</span> later. These quantities are often called the transition probabilities of the continuous-time Markov chain.</p>
<p>We can explicitly determine <span class="math inline">\(P_{ij}(t)\)</span> in the case of a pure birth process having distinct birth rates. For such a process, let <span class="math inline">\(X_k\)</span> denote the time the process spends in state <span class="math inline">\(k\)</span> before making a transition into state <span class="math inline">\(k+1\)</span>, <span class="math inline">\(k \geq 1\)</span>. Suppose that the process is presently in state <span class="math inline">\(i\)</span>, and let <span class="math inline">\(j &gt; i\)</span>. Then, as <span class="math inline">\(X_i\)</span> is the time it spends in state <span class="math inline">\(i\)</span> before moving to state <span class="math inline">\(i+1\)</span>, and <span class="math inline">\(X_{i+1}\)</span> is the time it then spends in state <span class="math inline">\(i+1\)</span> before moving to state <span class="math inline">\(i+2\)</span>, and so on, it follows that<br>
<span class="math display">\[\sum_{k=i}^{j-1} X_k\]</span><br>
is the time it takes until the process enters state <span class="math inline">\(j\)</span>. Now, if the process has not yet entered state <span class="math inline">\(j\)</span> by time <span class="math inline">\(t\)</span>, then its state at time <span class="math inline">\(t\)</span> is smaller than <span class="math inline">\(j\)</span>, and vice versa. That is,<br>
<span class="math display">\[X(t) &lt; j \iff X_i + \cdots + X_{j-1} &gt; t\]</span></p>
<p>Therefore, for <span class="math inline">\(i &lt; j\)</span>, we have for a pure birth process that<br>
<span class="math display">\[
\mathbb{P}\{X(t) &lt; j \mid X(0) = i\} = \mathbb{P}\left\{ \sum_{k=i}^{j-1} X_k &gt; t \right\}
\]</span></p>
<p>However, since <span class="math inline">\(X_i, \ldots, X_{j-1}\)</span> are independent exponential random variables with respective rates <span class="math inline">\(\lambda_i, \ldots, \lambda_{j-1}\)</span>, we obtain from the preceding and Eq. (5.9), which gives the tail distribution function of <span class="math inline">\(\sum_{k=i}^{j-1} X_k\)</span>, that<br>
<span class="math display">\[
\mathbb{P}\{X(t) &lt; j \mid X(0) = i\} = \sum_{k=i}^{j-1} e^{-\lambda_k t} \prod_{\substack{r=i \\ r \ne k}}^{j-1} \frac{\lambda_r}{\lambda_r - \lambda_k}
\]</span></p>
<p>Replacing <span class="math inline">\(j\)</span> by <span class="math inline">\(j+1\)</span> in the preceding gives<br>
<span class="math display">\[
\mathbb{P}\{X(t) &lt; j+1 \mid X(0) = i\} = \sum_{k=i}^{j} e^{-\lambda_k t} \prod_{\substack{r=i \\ r \ne k}}^{j} \frac{\lambda_r}{\lambda_r - \lambda_k}
\]</span></p>
<p>Since<br>
<span class="math display">\[
\mathbb{P}\{X(t) = j \mid X(0) = i\} = \mathbb{P}\{X(t) &lt; j+1 \mid X(0) = i\} - \mathbb{P}\{X(t) &lt; j \mid X(0) = i\}
\]</span><br>
and since <span class="math inline">\(P_{ii}(t) = \mathbb{P}\{X_i &gt; t\} = e^{-\lambda_i t}\)</span>, we have shown the following.</p>
<section id="proposition-6.1" class="level3">
<h3 class="anchored" data-anchor-id="proposition-6.1">Proposition 6.1</h3>
<p>For a pure birth process having <span class="math inline">\(\lambda_i \ne \lambda_j\)</span> when <span class="math inline">\(i \ne j\)</span>:</p>
<p><span class="math display">\[
P_{ij}(t) = \sum_{k=i}^{j} e^{-\lambda_k t} \prod_{\substack{r=i \\ r \ne k}}^{j} \frac{\lambda_r}{\lambda_r - \lambda_k} - \sum_{k=i}^{j-1} e^{-\lambda_k t} \prod_{\substack{r=i \\ r \ne k}}^{j-1} \frac{\lambda_r}{\lambda_r - \lambda_k}, \quad i &lt; j
\]</span></p>
<p><span class="math display">\[
P_{ii}(t) = e^{-\lambda_i t}
\]</span></p>
</section>
<section id="example-6.8" class="level3">
<h3 class="anchored" data-anchor-id="example-6.8">Example 6.8</h3>
<p>Consider the <strong>Yule process</strong>, which is a pure birth process in which each individual in the population independently gives birth at rate <span class="math inline">\(\lambda\)</span>, and so <span class="math inline">\(\lambda_n = n\lambda\)</span>, <span class="math inline">\(n \geq 1\)</span>. Letting <span class="math inline">\(i = 1\)</span>, we obtain from Proposition 6.1:</p>
<p><span class="math display">\[
P_{1j}(t) = \sum_{k=1}^{j} e^{-k\lambda t} \prod_{\substack{r=1 \\ r \ne k}}^{j} \frac{r}{r - k} - \sum_{k=1}^{j-1} e^{-k\lambda t} \prod_{\substack{r=1 \\ r \ne k}}^{j-1} \frac{r}{r - k}
\]</span></p>
<p>This simplifies to:<br>
<span class="math display">\[
P_{1j}(t) = e^{-j\lambda t} \prod_{r=1}^{j-1} \frac{r}{r - j} + \sum_{k=1}^{j-1} e^{-k\lambda t} \left( \prod_{\substack{r=1 \\ r \ne k}}^{j} \frac{r}{r - k} - \prod_{\substack{r=1 \\ r \ne k}}^{j-1} \frac{r}{r - k} \right)
\]</span></p>
<p>We can further simplify using:<br>
<span class="math display">\[
\frac{k}{j-k} \prod_{\substack{r=1 \\ r \ne k}}^{j-1} \frac{r}{r - k} = \frac{(j-1)!}{(1-k)(2-k)\cdots(k-1-k)(j-k)!} = (-1)^{k-1} \binom{j-1}{k-1}
\]</span></p>
<p>Hence:<br>
<span class="math display">\[
P_{1j}(t) = \sum_{k=1}^{j} \binom{j-1}{k-1} e^{-k\lambda t} (-1)^{k-1}
\]</span></p>
<p>Letting <span class="math inline">\(i = j - k\)</span>, and simplifying the index:<br>
<span class="math display">\[
P_{1j}(t) = e^{-\lambda t} \sum_{i=0}^{j-1} \binom{j-1}{i} e^{-i\lambda t} (-1)^i = e^{-\lambda t} (1 - e^{-\lambda t})^{j-1}
\]</span></p>
<p>Thus, starting with a single individual, the population size at time <span class="math inline">\(t\)</span> has a <strong>geometric distribution</strong> with mean <span class="math inline">\(e^{\lambda t}\)</span>. If the population starts with <span class="math inline">\(i\)</span> individuals, then we can regard each of these individuals as starting her own independent Yule process, and so the population at time <span class="math inline">\(t\)</span> will be the sum of <span class="math inline">\(i\)</span> independent and identically distributed geometric random variables with parameter <span class="math inline">\(e^{-\lambda t}\)</span>.</p>
<p>Hence, the population size at time <span class="math inline">\(t\)</span> has a <strong>negative binomial distribution</strong> with parameters <span class="math inline">\(i\)</span> and <span class="math inline">\(e^{-\lambda t}\)</span>, so:</p>
<p><span class="math display">\[
P_{ij}(t) = \binom{j-1}{i-1} e^{-i\lambda t} (1 - e^{-\lambda t})^{j-i}, \quad j \ge i \ge 1
\]</span></p>
</section>
<section id="example-6.9" class="level3">
<h3 class="anchored" data-anchor-id="example-6.9">Example 6.9</h3>
<p>An urn initially contains one type 1 and one type 2 ball. At each stage, a ball is chosen from the urn, with the chosen ball being equally likely to be any of the balls in the urn. If a type <span class="math inline">\(i\)</span> ball is chosen, then an experiment that is successful with probability <span class="math inline">\(p_i\)</span> is performed; if it is successful then the ball chosen along with a new type <span class="math inline">\(i\)</span> ball are put in the urn, and if it is unsuccessful then only the ball chosen is put in the urn, <span class="math inline">\(i = 1, 2\)</span>. We then move to the next stage.</p>
<p>We are interested in determining the mean numbers of type 1 and type 2 balls in the urn after <span class="math inline">\(n\)</span> stages.</p>
<p><strong>Solution:</strong><br>
To determine the mean numbers, for <span class="math inline">\(i = 1,2\)</span>, let <span class="math inline">\(m_i(j,k:r)\)</span> denote the mean number of type <span class="math inline">\(i\)</span> balls in the urn after the <span class="math inline">\(n\)</span> stages have elapsed, given that there are currently <span class="math inline">\(j\)</span> type 1 and <span class="math inline">\(k\)</span> type 2 balls in the urn, with a total of <span class="math inline">\(r\)</span> additional stages remaining. Also, let</p>
<p><span class="math display">\[
m(j,k:r) = (m_1(j,k:r), m_2(j,k:r))
\]</span></p>
<p>We need to determine <span class="math inline">\(m(1,1:n)\)</span>. To start, we derive recursive equations for <span class="math inline">\(m(j,k:r)\)</span> by conditioning on the first ball chosen and whether the resulting experiment is successful. This yields:</p>
<p><span class="math display">\[
m(j,k:r) = \frac{j}{j+k} [p_1 m(j+1,k:r-1) +
q_1 m(j,k:r-1)] +
\frac{k}{j+k} [p_2 m(j,k+1:r-1) +
q_2 m(j,k:r-1)]
\]</span></p>
<p>where <span class="math inline">\(q_i = 1 - p_i\)</span>, <span class="math inline">\(i = 1,2\)</span>.</p>
<p>Using the base case: <span class="math display">\[
m(j,k:0) = (j, k)
\]</span></p>
<p>we can use the recursion to determine the values of <span class="math inline">\(m(j,k:r)\)</span> for <span class="math inline">\(r = 1\)</span>, then <span class="math inline">\(r = 2\)</span>, and so on, up to <span class="math inline">\(r = n\)</span>.</p>
<hr>
<p>We can also derive an <strong>approximation</strong> for the mean numbers of type 1 and type 2 balls in the urn after <span class="math inline">\(n\)</span> stages by using a <em>Poissonization</em> trick.</p>
<p>Imagine that each ball in the urn, independently of the others, ‚Äúlights up‚Äù at times distributed as a Poisson process with rate <span class="math inline">\(\lambda = 1\)</span>. Suppose that each time a type <span class="math inline">\(i\)</span> ball lights up, we conduct the experiment that is successful with probability <span class="math inline">\(p_i\)</span>, and add a new type <span class="math inline">\(i\)</span> ball to the urn if it is successful.</p>
<p>Each time a ball lights up, say that a new stage has begun. For an urn with <span class="math inline">\(j\)</span> type 1 and <span class="math inline">\(k\)</span> type 2 balls, the next ball to light up will be of type 1 with probability <span class="math inline">\(\frac{j}{j+k}\)</span>. Thus, the numbers of type 1 and type 2 balls in the urn after successive stages are distributed exactly as in the original model.</p>
<p>Whenever there are <span class="math inline">\(j\)</span> type 1 balls, the time until the next type 1 ball lights up is the minimum of <span class="math inline">\(j\)</span> independent exponential random variables with rate 1, which is exponential with rate <span class="math inline">\(j\)</span>. Since with probability <span class="math inline">\(p_1\)</span> this results in a new type 1 ball being added, the time until the next type 1 ball is added is exponential with rate <span class="math inline">\(jp_1\)</span>.</p>
<p>Therefore, the number of type 1 balls in the urn over time is a <strong>Yule process</strong> with birth parameters: <span class="math display">\[
\lambda_1(j) = jp_1,\quad j \ge 1
\]</span></p>
<p>Similarly, for type 2: <span class="math display">\[
\lambda_2(j) = jp_2,\quad j \ge 1
\]</span></p>
<p>These two Yule processes are independent.</p>
<p>Let <span class="math inline">\(N_i(t)\)</span> be the number of type <span class="math inline">\(i\)</span> balls in the urn at time <span class="math inline">\(t\)</span>. Then: <span class="math display">\[
N_i(t) \sim \text{Geometric}(1 - e^{-p_i t}) \Rightarrow \mathbb{E}[N_i(t)] = e^{p_i t},\quad i = 1,2
\]</span></p>
<p>Let <span class="math inline">\(L_i(t)\)</span> be the number of times that a type <span class="math inline">\(i\)</span> ball has lit up by time <span class="math inline">\(t\)</span>. Then: <span class="math display">\[
\mathbb{E}[N_i(t)] = p_i \mathbb{E}[L_i(t)] + 1 \Rightarrow \mathbb{E}[L_i(t)] = \frac{e^{p_i t} - 1}{p_i},\quad i = 1,2
\]</span></p>
<p>Hence, the expected number of stages that have passed by time <span class="math inline">\(t\)</span> is: <span class="math display">\[
\mathbb{E}[L_1(t) + L_2(t)] = \frac{e^{p_1 t} - 1}{p_1} + \frac{e^{p_2 t} - 1}{p_2}
\]</span></p>
<p>Let <span class="math inline">\(t_n\)</span> be the value of <span class="math inline">\(t\)</span> that makes the above equal <span class="math inline">\(n\)</span>, i.e., <span class="math inline">\(t_n\)</span> solves: <span class="math display">\[
\frac{e^{p_1 t_n} - 1}{p_1} + \frac{e^{p_2 t_n} - 1}{p_2} = n
\]</span></p>
<p>Then we can approximate the expected number of type <span class="math inline">\(i\)</span> balls in the urn after <span class="math inline">\(n\)</span> stages by: <span class="math display">\[
\mathbb{E}[N_i(t_n)] = e^{p_i t_n},\quad i = 1,2
\]</span></p>
<hr>
<p><strong>Remarks:</strong></p>
<ol type="i">
<li><p>That <span class="math inline">\(\mathbb{E}[N_i(t)] = p_i \mathbb{E}[L_i(t)] + 1\)</span> is not immediate. The number of light ups affects the probability of success (e.g., larger <span class="math inline">\(L_i(t)\)</span> makes success more likely). So in general, <span class="math display">\[
\mathbb{E}[N_i(t) \mid L_i(t)] \ne p_i L_i(t) + 1
\]</span> However, the unconditional expectation formula <em>is</em> correct and can be proven using <strong>Wald‚Äôs equation</strong>, which will be presented in Section 7.3.</p></li>
<li><p>This example has been applied in <strong>drug testing</strong>. Suppose there are two drugs with unknown cure probabilities (<span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span>). At each stage, a patient receives a drug determined by drawing a ball. If a type <span class="math inline">\(i\)</span> ball is drawn, drug <span class="math inline">\(i\)</span> is used. A successful outcome results in another ball of the same type being added.</p></li>
<li><p>For <span class="math inline">\(p_1 = 0.7\)</span>, <span class="math inline">\(p_2 = 0.4\)</span>, after <span class="math inline">\(n = 500\)</span> stages:<br>
</p></li>
</ol>
<ul>
<li>True expected number of type 1 balls: 288.92<br>
</li>
<li>True expected number of type 2 balls: 36.47<br>
</li>
<li>Approximate values: 304.09 and 26.23</li>
</ul>
<p>After 1000 stages:<br>
- True means: 600.77 and 58.28<br>
- Approximations: 630.37 and 39.79</p>
<hr>
<p>We shall now derive a set of differential equations that the transition probabilities <span class="math inline">\(P_{ij}(t)\)</span> satisfy in a general continuous-time Markov chain. However, first we need a definition and a pair of lemmas.</p>
<p>For any pair of states <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, let <span class="math display">\[
q_{ij} = \nu_i P_{ij}
\]</span></p>
<p>Since <span class="math inline">\(\nu_i\)</span> is the rate at which the process makes a transition when in state <span class="math inline">\(i\)</span> and <span class="math inline">\(P_{ij}\)</span> is the probability that this transition is into state <span class="math inline">\(j\)</span>, it follows that <span class="math inline">\(q_{ij}\)</span> is the <strong>rate</strong>, when in state <span class="math inline">\(i\)</span>, at which the process makes a transition into state <span class="math inline">\(j\)</span>. The quantities <span class="math inline">\(q_{ij}\)</span> are called the <strong>instantaneous transition rates</strong>.</p>
<p>Since <span class="math display">\[
\nu_i = \sum_j \nu_i P_{ij} = \sum_j q_{ij}
\]</span> and <span class="math display">\[
P_{ij} = \frac{q_{ij}}{\nu_i} = \frac{q_{ij}}{\sum_j q_{ij}},
\]</span> it follows that specifying the instantaneous transition rates determines the parameters of the continuous-time Markov chain.</p>
<hr>
<p><strong>Lemma 6.2.</strong><br>
(a)<br>
<span class="math display">\[
\lim_{h \to 0} \frac{1 - P_{ii}(h)}{h} = \nu_i
\]</span></p>
<ol start="2" type="a">
<li><span class="math display">\[
\lim_{h \to 0} \frac{P_{ij}(h)}{h} = q_{ij}, \quad \text{when } i \ne j
\]</span></li>
</ol>
<p><strong>Proof.</strong><br>
We first note that since the amount of time until a transition occurs is exponentially distributed, it follows that the probability of two or more transitions in a time <span class="math inline">\(h\)</span> is <span class="math inline">\(o(h)\)</span> (i.e., vanishes faster than <span class="math inline">\(h\)</span>).</p>
<p>Thus, <span class="math inline">\(1 - P_{ii}(h)\)</span>, the probability that a process in state <span class="math inline">\(i\)</span> at time 0 will <strong>not</strong> be in state <span class="math inline">\(i\)</span> at time <span class="math inline">\(h\)</span>, equals the probability that a transition occurs within time <span class="math inline">\(h\)</span> plus something small compared to <span class="math inline">\(h\)</span>. Therefore, <span class="math display">\[
1 - P_{ii}(h) = \nu_i h + o(h)
\]</span> and part (a) is proven.</p>
<p>To prove part (b), we note that <span class="math inline">\(P_{ij}(h)\)</span>, the probability that the process goes from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> in a time <span class="math inline">\(h\)</span>, equals the probability that a transition occurs in this time multiplied by the probability that the transition is into state <span class="math inline">\(j\)</span>, plus something small compared to <span class="math inline">\(h\)</span>. That is, <span class="math display">\[
P_{ij}(h) = h \nu_i P_{ij} + o(h)
\]</span> and part (b) is proven. <span class="math inline">\(\blacksquare\)</span></p>
<hr>
<p><strong>Lemma 6.3.</strong><br>
For all <span class="math inline">\(s \ge 0\)</span>, <span class="math inline">\(t \ge 0\)</span>, <span class="math display">\[
P_{ij}(t + s) = \sum_{k=0}^{\infty} P_{ik}(t) P_{kj}(s) \tag{6.8}
\]</span></p>
<p><strong>Proof.</strong><br>
In order for the process to go from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> in time <span class="math inline">\(t + s\)</span>, it must be somewhere at time <span class="math inline">\(t\)</span>, and thus: <span class="math display">\[
P_{ij}(t + s) = \mathbb{P}\{X(t + s) = j \mid X(0) = i\}
\]</span></p>
<p>By the law of total probability: <span class="math display">\[
= \sum_{k=0}^{\infty} \mathbb{P}\{X(t + s) = j, X(t) = k \mid X(0) = i\}
\]</span></p>
<p>By conditional probability: <span class="math display">\[
= \sum_{k=0}^{\infty} \mathbb{P}\{X(t + s) = j \mid X(t) = k, X(0) = i\} \cdot \mathbb{P}\{X(t) = k \mid X(0) = i\}
\]</span></p>
<p>By the <strong>Markov property</strong>: <span class="math display">\[
= \sum_{k=0}^{\infty} \mathbb{P}\{X(t + s) = j \mid X(t) = k\} \cdot \mathbb{P}\{X(t) = k \mid X(0) = i\}
\]</span> <span class="math display">\[
= \sum_{k=0}^{\infty} P_{kj}(s) P_{ik}(t)
\]</span> and the proof is completed. <span class="math inline">\(\blacksquare\)</span></p>
<p>The set of equations (6.8) is known as the <strong>Chapman‚ÄìKolmogorov equations</strong>.</p>
<p>From Lemma 6.3, we obtain: <span class="math display">\[
P_{ij}(h + t) - P_{ij}(t) = \sum_{k \ne i} P_{ik}(h) P_{kj}(t) - [1 - P_{ii}(h)] P_{ij}(t)
\]</span></p>
<p>Thus, <span class="math display">\[
\frac{P_{ij}(t + h) - P_{ij}(t)}{h} = \sum_{k \ne i} \frac{P_{ik}(h)}{h} P_{kj}(t) - \frac{1 - P_{ii}(h)}{h} P_{ij}(t)
\]</span></p>
<p>Now, assuming that we can interchange the limit and the summation, and applying Lemma 6.2: <span class="math display">\[
\lim_{h \to 0} \frac{P_{ij}(t + h) - P_{ij}(t)}{h} = \sum_{k \ne i} q_{ik} P_{kj}(t) - \nu_i P_{ij}(t)
\]</span></p>
<p>It turns out that this interchange can indeed be justified, and hence‚Ä¶</p>
</section>
<section id="theorem-6.1-kolmogorovs-backward-equations" class="level3">
<h3 class="anchored" data-anchor-id="theorem-6.1-kolmogorovs-backward-equations">Theorem 6.1 (Kolmogorov‚Äôs Backward Equations)</h3>
<p>For all states <span class="math inline">\(i, j\)</span>, and times <span class="math inline">\(t \geq 0\)</span>, <span class="math display">\[
\frac{d}{dt} P_{ij}(t) = \sum_{k \ne i} q_{ik} P_{kj}(t) - \nu_i P_{ij}(t)
\]</span></p>
<hr>
</section>
<section id="example-6.10" class="level3">
<h3 class="anchored" data-anchor-id="example-6.10">Example 6.10</h3>
<p><strong>The backward equations for the pure birth process become:</strong> <span class="math display">\[
\frac{d}{dt} P_{ij}(t) = \lambda_i P_{i+1,j}(t) - \lambda_i P_{ij}(t)
\]</span></p>
<p><strong>The backward equations for the birth and death process become:</strong></p>
<p>For <span class="math inline">\(i = 0\)</span>: <span class="math display">\[
\frac{d}{dt} P_{0j}(t) = \lambda_0 [P_{1j}(t) - P_{0j}(t)]
\]</span></p>
<p>For <span class="math inline">\(i &gt; 0\)</span>: <span class="math display">\[
\frac{d}{dt} P_{ij}(t) = \lambda_i P_{i+1,j}(t) + \mu_i P_{i-1,j}(t) - (\lambda_i + \mu_i) P_{ij}(t) \tag{6.9}
\]</span></p>
<hr>
</section>
<section id="example-6.11-a-continuous-time-markov-chain-consisting-of-two-states" class="level3">
<h3 class="anchored" data-anchor-id="example-6.11-a-continuous-time-markov-chain-consisting-of-two-states">Example 6.11 (A Continuous-Time Markov Chain Consisting of Two States)</h3>
<p>Consider a machine that works for an exponential amount of time with mean <span class="math inline">\(1/\lambda\)</span> before breaking down; and suppose that it takes an exponential amount of time with mean <span class="math inline">\(1/\mu\)</span> to repair the machine.</p>
<p>Let state 0 = ‚Äúworking‚Äù, and state 1 = ‚Äúunder repair‚Äù.</p>
<p><strong>Parameters:</strong> - <span class="math inline">\(\lambda_0 = \lambda\)</span>, <span class="math inline">\(\mu_1 = \mu\)</span> - <span class="math inline">\(\lambda_i = 0\)</span> for <span class="math inline">\(i \ne 0\)</span>, <span class="math inline">\(\mu_i = 0\)</span> for <span class="math inline">\(i \ne 1\)</span></p>
<p>From the backward equations: - Equation (6.10): <span class="math display">\[
  \frac{d}{dt} P_{00}(t) = \lambda [P_{10}(t) - P_{00}(t)]
  \]</span> - Equation (6.11): <span class="math display">\[
  \frac{d}{dt} P_{10}(t) = \mu P_{00}(t) - \mu P_{10}(t)
  \]</span></p>
<p>Multiply (6.10) by <span class="math inline">\(\mu\)</span>, and (6.11) by <span class="math inline">\(\lambda\)</span>, then add: <span class="math display">\[
\mu \frac{d}{dt} P_{00}(t) + \lambda \frac{d}{dt} P_{10}(t) = 0
\]</span></p>
<p>Integrating: <span class="math display">\[
\mu P_{00}(t) + \lambda P_{10}(t) = \mu \tag{6.12}
\]</span></p>
<p>From this, <span class="math display">\[
\lambda P_{10}(t) = \mu[1 - P_{00}(t)]
\]</span></p>
<p>Substitute into (6.10): <span class="math display">\[
\frac{d}{dt} P_{00}(t) = \mu[1 - P_{00}(t)] - \lambda P_{00}(t) = \mu - (\mu + \lambda) P_{00}(t)
\]</span></p>
<p>Let <span class="math inline">\(h(t) = P_{00}(t) - \frac{\mu}{\mu + \lambda}\)</span>, then: <span class="math display">\[
h'(t) = -(\mu + \lambda) h(t) \Rightarrow h(t) = K e^{-(\mu + \lambda)t}
\]</span></p>
<p>Use initial condition <span class="math inline">\(P_{00}(0) = 1\)</span>: <span class="math display">\[
P_{00}(t) = \frac{\lambda}{\mu + \lambda} e^{-(\mu + \lambda)t} + \frac{\mu}{\mu + \lambda}
\]</span></p>
<p>From (6.12), we also get: <span class="math display">\[
P_{10}(t) = \frac{\mu}{\mu + \lambda} \left(1 - e^{-(\mu + \lambda)t} \right)
\]</span></p>
<p>Thus, the probability that the machine is working at time <span class="math inline">\(t = 10\)</span> is: <span class="math display">\[
P_{00}(10) = \frac{\lambda}{\mu + \lambda} e^{-10(\mu + \lambda)} + \frac{\mu}{\mu + \lambda}
\]</span></p>
<hr>
</section>
<section id="kolmogorovs-forward-equations" class="level3">
<h3 class="anchored" data-anchor-id="kolmogorovs-forward-equations">Kolmogorov‚Äôs Forward Equations</h3>
<p>From the Chapman‚ÄìKolmogorov equations: <span class="math display">\[
P_{ij}(t + h) - P_{ij}(t) = \sum_{k \ne j} P_{ik}(t) P_{kj}(h) - [1 - P_{jj}(h)] P_{ij}(t)
\]</span></p>
<p>Divide by <span class="math inline">\(h\)</span> and take the limit: <span class="math display">\[
\frac{d}{dt} P_{ij}(t) = \sum_{k \ne j} q_{kj} P_{ik}(t) - \nu_j P_{ij}(t)
\]</span></p>
<p>This leads to the next theorem.</p>
<hr>
</section>
<section id="theorem-6.2-kolmogorovs-forward-equations" class="level3">
<h3 class="anchored" data-anchor-id="theorem-6.2-kolmogorovs-forward-equations">Theorem 6.2 (Kolmogorov‚Äôs Forward Equations)</h3>
<p>Under suitable regularity conditions, <span class="math display">\[
\frac{d}{dt} P_{ij}(t) = \sum_{k \ne j} q_{kj} P_{ik}(t) - \nu_j P_{ij}(t) \tag{6.13}
\]</span></p>
<hr>
<p>We now solve the forward equations for the <strong>pure birth process</strong>. For this case, (6.13) becomes: <span class="math display">\[
\frac{d}{dt} P_{ij}(t) = \lambda_{j-1} P_{i,j-1}(t) - \lambda_j P_{ij}(t)
\]</span></p>
<p>Since <span class="math inline">\(P_{ij}(t) = 0\)</span> when <span class="math inline">\(j &lt; i\)</span>, we can write: <span class="math display">\[
\frac{d}{dt} P_{ii}(t) = -\lambda_i P_{ii}(t) \\
\frac{d}{dt} P_{ij}(t) = \lambda_{j-1} P_{i,j-1}(t) - \lambda_j P_{ij}(t), \quad j \ge i+1 \tag{6.14}
\]</span></p>
<hr>
</section>
<section id="proposition-6.4" class="level3">
<h3 class="anchored" data-anchor-id="proposition-6.4">Proposition 6.4</h3>
<p>For a pure birth process: <span class="math display">\[
P_{ii}(t) = e^{-\lambda_i t}, \quad i \ge 0
\]</span> <span class="math display">\[
P_{ij}(t) = \lambda_{j-1} e^{-\lambda_j t} \int_0^t e^{\lambda_j s} P_{i,j-1}(s) \, ds, \quad j \ge i + 1
\]</span></p>
<p><strong>Proof sketch:</strong> Integrate both sides of (6.14) using the integrating factor <span class="math inline">\(e^{\lambda_j t}\)</span> and initial condition <span class="math inline">\(P_{ij}(0) = 0\)</span>.</p>
<hr>
</section>
<section id="example-6.12-forward-equations-for-birth-and-death-process" class="level3">
<h3 class="anchored" data-anchor-id="example-6.12-forward-equations-for-birth-and-death-process">Example 6.12 (Forward Equations for Birth and Death Process)</h3>
<p>Using Eq. (6.13), for the birth-death process we get:</p>
<p>For <span class="math inline">\(j = 0\)</span>: <span class="math display">\[
\frac{d}{dt} P_{i0}(t) = \mu_1 P_{i1}(t) - \lambda_0 P_{i0}(t) \tag{6.15}
\]</span></p>
<p>For <span class="math inline">\(j \ge 1\)</span>: <span class="math display">\[
\frac{d}{dt} P_{ij}(t) = \lambda_{j-1} P_{i,j-1}(t) + \mu_{j+1} P_{i,j+1}(t) - (\lambda_j + \mu_j) P_{ij}(t) \tag{6.16}
\]</span></p>
</section>
</section>
<section id="limiting-probabilities" class="level2">
<h2 class="anchored" data-anchor-id="limiting-probabilities">6.5 Limiting Probabilities</h2>
<p>In analogy with a basic result in discrete-time Markov chains, the probability that a continuous-time Markov chain will be in state <span class="math inline">\(j\)</span> at time <span class="math inline">\(t\)</span> often converges to a limiting value that is independent of the initial state. That is, if we call this value <span class="math inline">\(P_j\)</span>, then <span class="math display">\[
P_j \equiv \lim_{t \to \infty} P_{ij}(t)
\]</span> where we assume the limit exists and is independent of the initial state <span class="math inline">\(i\)</span>.</p>
<p>To derive a set of equations for the <span class="math inline">\(P_j\)</span>, consider the forward equations: <span class="math display">\[
\frac{d}{dt} P_{ij}(t) = \sum_{k \ne j} q_{kj} P_{ik}(t) - \nu_j P_{ij}(t) \tag{6.17}
\]</span></p>
<p>Letting <span class="math inline">\(t \to \infty\)</span> and assuming we can interchange the limit and summation: <span class="math display">\[
\lim_{t \to \infty} \frac{d}{dt} P_{ij}(t) = \sum_{k \ne j} q_{kj} P_k - \nu_j P_j
\]</span></p>
<p>But since <span class="math inline">\(P_{ij}(t)\)</span> is a bounded function, its derivative must converge to 0: <span class="math display">\[
0 = \sum_{k \ne j} q_{kj} P_k - \nu_j P_j
\]</span></p>
<p>That is, <span class="math display">\[
\nu_j P_j = \sum_{k \ne j} q_{kj} P_k, \quad \text{for all states } j \tag{6.18}
\]</span></p>
<p>Along with the normalization condition: <span class="math display">\[
\sum_j P_j = 1 \tag{6.19}
\]</span></p>
<p>This system can be used to solve for the limiting probabilities.</p>
<hr>
<p><strong>Remarks:</strong></p>
<ol type="i">
<li>We have assumed that the limiting probabilities <span class="math inline">\(P_j\)</span> exist. A sufficient condition is:</li>
</ol>
<ul>
<li><ol type="a">
<li>All states communicate (i.e., from any state <span class="math inline">\(i\)</span> there‚Äôs positive probability of reaching any <span class="math inline">\(j\)</span>).</li>
</ol></li>
<li><ol start="2" type="a">
<li>The chain is positive recurrent (the mean return time to any state is finite).</li>
</ol></li>
</ul>
<p>If (a) and (b) hold, then <span class="math inline">\(P_j\)</span> exists, satisfies (6.18) and (6.19), and <span class="math inline">\(P_j\)</span> also represents the long-run proportion of time spent in state <span class="math inline">\(j\)</span>.</p>
<ol start="2" type="i">
<li>Eq. (6.18) has a <strong>balance equation</strong> interpretation:<br>
In the long run, the rate at which transitions <strong>enter</strong> state <span class="math inline">\(j\)</span> equals the rate at which transitions <strong>leave</strong> state <span class="math inline">\(j\)</span>:</li>
</ol>
<ul>
<li>Rate leaving state <span class="math inline">\(j\)</span>: <span class="math inline">\(\nu_j P_j\)</span></li>
<li>Rate entering from <span class="math inline">\(k\)</span>: <span class="math inline">\(q_{kj} P_k\)</span> Thus: <span class="math display">\[
\sum_{k \ne j} q_{kj} P_k = \nu_j P_j
\]</span></li>
</ul>
<hr>
<section id="limiting-probabilities-for-a-birth-and-death-process" class="level3">
<h3 class="anchored" data-anchor-id="limiting-probabilities-for-a-birth-and-death-process">Limiting Probabilities for a Birth and Death Process</h3>
<p>From (6.18), or by balancing rate in = rate out, we obtain:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>State</th>
<th>Leave rate = Enter rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td><span class="math inline">\(\lambda_0 P_0 = \mu_1 P_1\)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td><span class="math inline">\((\lambda_1 + \mu_1) P_1 = \mu_2 P_2 + \lambda_0 P_0\)</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math inline">\((\lambda_2 + \mu_2) P_2 = \mu_3 P_3 + \lambda_1 P_1\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
</tbody>
</table>
<p>Adding each equation to the previous yields: <span class="math display">\[
\lambda_0 P_0 = \mu_1 P_1 \\
\lambda_1 P_1 = \mu_2 P_2 \\
\lambda_2 P_2 = \mu_3 P_3 \\
\vdots
\]</span></p>
<p>Solving recursively in terms of <span class="math inline">\(P_0\)</span>: <span class="math display">\[
P_1 = \frac{\lambda_0}{\mu_1} P_0 \\
P_2 = \frac{\lambda_1}{\mu_2} P_1 = \frac{\lambda_1 \lambda_0}{\mu_2 \mu_1} P_0 \\
\cdots \\
P_n = \frac{\lambda_0 \lambda_1 \cdots \lambda_{n-1}}{\mu_1 \mu_2 \cdots \mu_n} P_0
\]</span></p>
<p>Using normalization <span class="math inline">\(\sum_{n=0}^\infty P_n = 1\)</span>: <span class="math display">\[
P_0 = \left( 1 + \sum_{n=1}^\infty \frac{\lambda_0 \lambda_1 \cdots \lambda_{n-1}}{\mu_1 \mu_2 \cdots \mu_n} \right)^{-1}
\]</span></p>
<p>So: <span class="math display">\[
P_n = \frac{\lambda_0 \cdots \lambda_{n-1}}{\mu_1 \cdots \mu_n} P_0, \quad n \ge 1 \tag{6.20}
\]</span></p>
<p><strong>Existence condition:</strong><br>
The limiting probabilities exist if: <span class="math display">\[
\sum_{n=1}^\infty \frac{\lambda_0 \cdots \lambda_{n-1}}{\mu_1 \cdots \mu_n} &lt; \infty \tag{6.21}
\]</span></p>
<hr>
</section>
<section id="examples" class="level3">
<h3 class="anchored" data-anchor-id="examples">Examples:</h3>
<p><strong>Multiserver Exponential Queue (Example 6.6):</strong></p>
<p>Condition (6.21) reduces to: <span class="math display">\[
\sum_{n=s+1}^\infty \frac{\lambda^n}{(s\mu)^n} &lt; \infty
\quad \Rightarrow \quad \lambda &lt; s\mu
\]</span></p>
<hr>
<p><strong>Linear Growth Model with Immigration (Example 6.4):</strong></p>
<p>Condition (6.21) becomes: <span class="math display">\[
\sum_{n=1}^\infty \frac{\theta(\theta + \lambda) \cdots (\theta + (n - 1)\lambda)}{n! \mu^n}
\]</span></p>
<p>Apply ratio test: <span class="math display">\[
\lim_{n \to \infty} \frac{\theta + n\lambda}{(n + 1)\mu} = \frac{\lambda}{\mu} &lt; 1
\quad \Rightarrow \text{Converges if } \lambda &lt; \mu
\]</span></p>
<hr>
</section>
<section id="example-6.13-machine-repair-model" class="level3">
<h3 class="anchored" data-anchor-id="example-6.13-machine-repair-model">Example 6.13 (Machine Repair Model)</h3>
<ul>
<li><span class="math inline">\(M\)</span> machines, one repairman</li>
<li>Time to fail: <span class="math inline">\(\text{Exp}(1/\lambda)\)</span>, repair time: <span class="math inline">\(\text{Exp}(1/\mu)\)</span></li>
<li>Let state <span class="math inline">\(n\)</span> be the number of failed machines</li>
</ul>
<p>Parameters: - <span class="math inline">\(\mu_n = \mu\)</span>, <span class="math inline">\(n \ge 1\)</span> - <span class="math inline">\(\lambda_n = (M - n)\lambda\)</span>, <span class="math inline">\(n \le M\)</span>; <span class="math inline">\(\lambda_n = 0\)</span> otherwise</p>
<p>From (6.20): - <span class="math inline">\(P_0 = \left(1 + \sum_{n=1}^M \frac{(M\lambda)(M-1)\lambda \cdots (M - n + 1)\lambda}{\mu^n} \right)^{-1}\)</span> - Simplifies to: <span class="math display">\[
  P_0 = \left(1 + \sum_{n=1}^M \frac{(\lambda/\mu)^n M!}{(M - n)!} \right)^{-1}
  \]</span> <span class="math display">\[
  P_n = \frac{(\lambda/\mu)^n M!}{(M - n)!} \cdot P_0, \quad n = 0, \dots, M
  \]</span></p>
<p><strong>Average number of machines not in use:</strong> <span class="math display">\[
\sum_{n=0}^M n P_n = \frac{\sum_{n=0}^M n (\lambda/\mu)^n M! / (M - n)!}{1 + \sum_{n=1}^M (\lambda/\mu)^n M! / (M - n)!} \tag{6.22}
\]</span></p>
<p><strong>Proportion of time a given machine is working:</strong> <span class="math display">\[
1 - \frac{1}{M} \sum_{n=0}^M n P_n
\]</span></p>
<hr>
</section>
<section id="example-6.14-the-mm1-queue" class="level3">
<h3 class="anchored" data-anchor-id="example-6.14-the-mm1-queue">Example 6.14 (The M/M/1 Queue)</h3>
<ul>
<li><span class="math inline">\(\lambda_n = \lambda\)</span>, <span class="math inline">\(\mu_n = \mu\)</span></li>
<li>From (6.20): <span class="math display">\[
P_n = \frac{(\lambda/\mu)^n}{1 + \sum_{k=1}^\infty (\lambda/\mu)^k} = (\lambda/\mu)^n (1 - \lambda/\mu), \quad n \ge 0
\]</span></li>
<li>Valid only if <span class="math inline">\(\lambda &lt; \mu\)</span>.</li>
</ul>
<hr>
</section>
<section id="example-6.15-shoe-shine-shop" class="level3">
<h3 class="anchored" data-anchor-id="example-6.15-shoe-shine-shop">Example 6.15 (Shoe Shine Shop)</h3>
<ul>
<li>3 states: 0, 1, 2 (number of customers)</li>
<li>Transitions: 2 ‚Üí 0 possible, not birth-death</li>
<li>Use balance equations:</li>
</ul>
<table class="caption-top table">
<thead>
<tr class="header">
<th>State</th>
<th>Leave rate = Enter rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td><span class="math inline">\(\lambda P_0 = \mu_2 P_2\)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td><span class="math inline">\(\mu_1 P_1 = \lambda P_0\)</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math inline">\(\mu_2 P_2 = \mu_1 P_1\)</span></td>
</tr>
</tbody>
</table>
<p>Solve: - <span class="math inline">\(P_1 = \frac{\lambda}{\mu_1} P_0\)</span>, <span class="math inline">\(P_2 = \frac{\lambda}{\mu_2} P_0\)</span></p>
<p>Normalize: <span class="math display">\[
P_0 = \frac{\mu_1 \mu_2}{\mu_1 \mu_2 + \lambda (\mu_1 + \mu_2)}
\]</span></p>
<p>So: <span class="math display">\[
P_1 = \frac{\lambda \mu_2}{\mu_1 \mu_2 + \lambda (\mu_1 + \mu_2)}, \quad
P_2 = \frac{\lambda \mu_1}{\mu_1 \mu_2 + \lambda (\mu_1 + \mu_2)}
\]</span></p>
<hr>
</section>
<section id="example-6.16-preemptive-repair-with-n-components" class="level3">
<h3 class="anchored" data-anchor-id="example-6.16-preemptive-repair-with-n-components">Example 6.16 (Preemptive Repair with n Components)</h3>
<ul>
<li><span class="math inline">\(n\)</span> components, one repairman</li>
<li>Each component <span class="math inline">\(i\)</span> fails with rate <span class="math inline">\(\lambda_i\)</span>, repaired with rate <span class="math inline">\(\mu_i\)</span></li>
<li>Most recent failure is repaired first (preemption allowed)</li>
<li>State: ordered list of failed components</li>
</ul>
<p>Number of states: <span class="math display">\[
\sum_{k=0}^n \binom{n}{k} k! = n! \sum_{i=0}^n \frac{1}{i!}
\]</span></p>
<p>Let <span class="math inline">\(P(i_1, ..., i_k)\)</span> be the steady-state probability of state <span class="math inline">\((i_1, ..., i_k)\)</span>.</p>
<p>Balance equations: - Exit rate from <span class="math inline">\((i_1, ..., i_k)\)</span>: <span class="math display">\[
  \mu_{i_1} + \sum_{\substack{i \ne i_j \\ j=1..k}} \lambda_i
  \]</span> - Entry: - From <span class="math inline">\((i_2, ..., i_k)\)</span> if <span class="math inline">\(i_1\)</span> fails - From <span class="math inline">\((i, i_1, ..., i_k)\)</span> if <span class="math inline">\(i\)</span> (not in list) is repaired</p>
<p>Let <span class="math display">\[
P(i_1, ..., i_k) = \frac{\lambda_{i_1} \cdots \lambda_{i_k}}{\mu_{i_1} \cdots \mu_{i_k}} P(\varnothing) \tag{6.24}
\]</span></p>
<p>Normalization: <span class="math display">\[
P(\varnothing) = \left[ 1 + \sum_{i_1,...,i_k} \frac{\lambda_{i_1} \cdots \lambda_{i_k}}{\mu_{i_1} \cdots \mu_{i_k}} \right]^{-1}
\]</span></p>
<p><strong>Example with <span class="math inline">\(n = 2\)</span></strong>: states: <span class="math inline">\(\varnothing\)</span>, 1, 2, 12, 21</p>
<ul>
<li><span class="math inline">\(P(1) = \frac{\lambda_1}{\mu_1} P(\varnothing)\)</span></li>
<li><span class="math inline">\(P(2) = \frac{\lambda_2}{\mu_2} P(\varnothing)\)</span></li>
<li><span class="math inline">\(P(1,2) = P(2,1) = \frac{\lambda_1 \lambda_2}{\mu_1 \mu_2} P(\varnothing)\)</span></li>
<li>Normalize: <span class="math display">\[
P(\varnothing) = \left[ 1 + \frac{\lambda_1}{\mu_1} + \frac{\lambda_2}{\mu_2} + 2 \cdot \frac{\lambda_1 \lambda_2}{\mu_1 \mu_2} \right]^{-1}
\]</span></li>
</ul>
<p><strong>Observation</strong>: given the set of failed components, all orderings are equally likely.</p>
<hr>
<p>When the limiting probabilities exist, we say the chain is <strong>ergodic</strong>. The <span class="math inline">\(P_j\)</span> are also called <strong>stationary probabilities</strong>, because if the chain starts in state <span class="math inline">\(j\)</span> with probability <span class="math inline">\(P_j\)</span>, then: <span class="math display">\[
\mathbb{P}(X(t) = j) = P_j, \quad \text{for all } t
\]</span></p>
<p><strong>Verification:</strong> Assume initial state distributed as <span class="math inline">\(\{P_j\}\)</span>: <span class="math display">\[
\mathbb{P}(X(t) = j) = \sum_k P_{kj}(t) P_k = \lim_{s \to \infty} \sum_k P_{kj}(t) P_{ik}(s) = \lim_{s \to \infty} P_{ij}(t + s) = P_j
\]</span> (by Chapman‚ÄìKolmogorov and limit properties)</p>
</section>
</section>
<section id="time-reversibility" class="level2">
<h2 class="anchored" data-anchor-id="time-reversibility">6.6 Time Reversibility</h2>
<p>Consider a continuous-time Markov chain that is <strong>ergodic</strong>, and let <span class="math inline">\(P_i\)</span> denote its limiting probabilities. If we ignore the time spent in each state and just look at the <strong>sequence of states visited</strong>, it forms a discrete-time Markov chain (called the <strong>embedded chain</strong>) with transition probabilities <span class="math inline">\(P_{ij}\)</span>. Let <span class="math inline">\(\pi_i\)</span> be the limiting probabilities of this embedded chain, satisfying:</p>
<p><span class="math display">\[
\pi_i = \sum_j \pi_j P_{ji}, \quad \sum_i \pi_i = 1
\]</span></p>
<p>Since <span class="math inline">\(\pi_i\)</span> is the proportion of <strong>transitions</strong> into state <span class="math inline">\(i\)</span>, and <span class="math inline">\(1/\nu_i\)</span> is the mean time spent in state <span class="math inline">\(i\)</span> per visit, it‚Äôs intuitive that <span class="math inline">\(P_i\)</span>, the proportion of <strong>time</strong> in state <span class="math inline">\(i\)</span>, is:</p>
<p><span class="math display">\[
P_i = \frac{\pi_i / \nu_i}{\sum_j \pi_j / \nu_j} \tag{6.25}
\]</span></p>
<p>This is confirmed via the balance equation: <span class="math display">\[
\nu_i P_i = \sum_{j \ne i} P_j q_{ji} = \sum_j P_j \nu_j P_{ji}
\]</span></p>
<p>Suppose the chain is observed in <strong>steady state</strong>, and we <strong>reverse</strong> time from some time <span class="math inline">\(T\)</span>. The reversed process is also a continuous-time Markov chain, with: - Sojourn times in each state still exponential with rate <span class="math inline">\(\nu_i\)</span> - Transition probabilities: <span class="math display">\[
Q_{ij} = \frac{\pi_j P_{ji}}{\pi_i}
\]</span></p>
<p>Thus, the reversed process has same rates and is <strong>time reversible</strong> if: <span class="math display">\[
\pi_i P_{ij} = \pi_j P_{ji}, \quad \forall i, j
\]</span></p>
<p>Given: <span class="math display">\[
P_i = \frac{\pi_i / \nu_i}{\sum_j \pi_j / \nu_j}
\]</span></p>
<p>This condition becomes: <span class="math display">\[
P_i q_{ij} = P_j q_{ji} \tag{6.26}
\]</span></p>
<p><strong>Interpretation</strong>:<br>
In time-reversible chains, the <strong>rate</strong> of direct transitions from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span> equals the rate from <span class="math inline">\(j\)</span> to <span class="math inline">\(i\)</span>.</p>
<hr>
<section id="proposition-6.5" class="level3">
<h3 class="anchored" data-anchor-id="proposition-6.5">Proposition 6.5</h3>
<p><strong>An ergodic birth and death process is time reversible.</strong></p>
<p><strong>Proof sketch</strong>: In any interval, the number of transitions from <span class="math inline">\(i\)</span> to <span class="math inline">\(i+1\)</span> differs by at most 1 from transitions from <span class="math inline">\(i+1\)</span> to <span class="math inline">\(i\)</span>. Hence, over long time, their rates must be equal.</p>
<hr>
</section>
<section id="corollary-6.6" class="level3">
<h3 class="anchored" data-anchor-id="corollary-6.6">Corollary 6.6</h3>
<p><strong>In an M/M/s queue with <span class="math inline">\(\lambda &lt; s\mu\)</span>, the departure process is a Poisson process with rate <span class="math inline">\(\lambda\)</span> (in steady state).</strong></p>
<p><strong>Reason</strong>: The process is time reversible. In forward time, arrivals are Poisson. So in reverse, ‚Äúarrivals‚Äù are actually departures in forward time ‚áí Poisson.</p>
<hr>
</section>
<section id="example-6.17-queue-occupancy-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="example-6.17-queue-occupancy-interpretation">Example 6.17 (Queue Occupancy Interpretation)</h3>
<p>Let C be a customer in an <strong>M/M/1</strong> queue with arrival rate <span class="math inline">\(\lambda\)</span> and service rate <span class="math inline">\(\mu\)</span> (<span class="math inline">\(\lambda &lt; \mu\)</span>). Given that C spends time <span class="math inline">\(t\)</span> in the system, what‚Äôs the distribution of the number of others present at their arrival?</p>
<p><strong>Solution</strong>:<br>
By reversibility, number of departures in <span class="math inline">\((s, s+t)\)</span> is equal in distribution to number of <strong>arrivals</strong> in that interval in the reversed process. Thus, this number is <strong>Poisson(<span class="math inline">\(\lambda t\)</span>)</strong>.</p>
</section>
<section id="proposition-6.7" class="level3">
<h3 class="anchored" data-anchor-id="proposition-6.7">Proposition 6.7</h3>
<p>Suppose that an ergodic continuous-time Markov chain has transition rates <span class="math inline">\(q_{ij}\)</span> and limiting probabilities <span class="math inline">\(P_i\)</span>. If <span class="math display">\[
P_i q_{ij} = P_j q_{ji} \quad \text{for all } i, j \tag{6.27}
\]</span> then the process is <strong>time reversible</strong>.</p>
<p><strong>Proof sketch</strong>:<br>
From this condition, it‚Äôs easy to verify that the reversed process has the same dynamics as the forward process. Specifically, the reversed transition rates <span class="math inline">\(q_{ij}^*\)</span> become: <span class="math display">\[
q_{ij}^* = \frac{P_j q_{ji}}{P_i} = q_{ij}
\]</span> Thus, the reversed process has the same generator matrix <span class="math inline">\(Q\)</span>, hence same law.</p>
<hr>
</section>
<section id="example-6.18-two-server-queue" class="level3">
<h3 class="anchored" data-anchor-id="example-6.18-two-server-queue">Example 6.18 (Two-Server Queue)</h3>
<p>A two-server queue has a maximum of three customers. Arrivals follow a Poisson process with rate <span class="math inline">\(\lambda\)</span> and service is exponential with rate <span class="math inline">\(\mu\)</span> per server.</p>
<p>States: 0, 1, 2, 3 (number of customers)</p>
<p>Transition diagram: - <span class="math inline">\(0 \xrightarrow{\lambda} 1\)</span> - <span class="math inline">\(1 \xrightarrow{\lambda} 2\)</span>, <span class="math inline">\(1 \xrightarrow{\mu} 0\)</span> - <span class="math inline">\(2 \xrightarrow{\lambda} 3\)</span>, <span class="math inline">\(2 \xrightarrow{2\mu} 1\)</span> - <span class="math inline">\(3 \xrightarrow{2\mu} 2\)</span></p>
<p>Let‚Äôs check time reversibility: - Solve for stationary probabilities: <span class="math display">\[
  P_1 = \frac{\lambda}{\mu} P_0,\quad
  P_2 = \frac{\lambda}{2\mu} P_1 = \frac{\lambda^2}{2\mu^2} P_0,\quad
  P_3 = \frac{\lambda}{2\mu} P_2 = \frac{\lambda^3}{4\mu^3} P_0
  \]</span></p>
<p>Normalization: <span class="math display">\[
P_0 = \left(1 + \frac{\lambda}{\mu} + \frac{\lambda^2}{2\mu^2} + \frac{\lambda^3}{4\mu^3}\right)^{-1}
\]</span></p>
<p>Now check detailed balance: <span class="math display">\[
P_0 \cdot \lambda = P_1 \cdot \mu \quad \text{‚úì} \\
P_1 \cdot \lambda = P_2 \cdot 2\mu \quad \text{‚úì} \\
P_2 \cdot \lambda = P_3 \cdot 2\mu \quad \text{‚úì}
\]</span></p>
<p>Thus, the process is <strong>time reversible</strong>.</p>
<hr>
</section>
<section id="example-6.19-jackson-network" class="level3">
<h3 class="anchored" data-anchor-id="example-6.19-jackson-network">Example 6.19 (Jackson Network)</h3>
<p>Let a network consist of <span class="math inline">\(n\)</span> service stations. Customers: - arrive from outside to station <span class="math inline">\(i\)</span> at rate <span class="math inline">\(r_i\)</span>, - get served (service rate <span class="math inline">\(\mu_i\)</span>), - then with probability <span class="math inline">\(P_{ij}\)</span> go to station <span class="math inline">\(j\)</span>, or - with probability <span class="math inline">\(1 - \sum_j P_{ij}\)</span> leave the system.</p>
<p>Let <span class="math inline">\(\lambda_i\)</span> be the <strong>total arrival rate</strong> to station <span class="math inline">\(i\)</span> (external + internal). Then: <span class="math display">\[
\lambda_i = r_i + \sum_{j=1}^n \lambda_j P_{ji}
\]</span></p>
<p>This is a system of <strong>traffic equations</strong>. Once solved, define the <strong>utilization</strong> of station <span class="math inline">\(i\)</span>: <span class="math display">\[
\rho_i = \frac{\lambda_i}{\mu_i}
\]</span></p>
<p>If all <span class="math inline">\(\rho_i &lt; 1\)</span>, then in steady state the queue at station <span class="math inline">\(i\)</span> behaves like an M/M/1 queue.</p>
<p>The network has <strong>product-form solution</strong>: <span class="math display">\[
P(n_1, ..., n_n) = \prod_{i=1}^n (1 - \rho_i) \rho_i^{n_i}
\]</span></p>
<p>This process is <strong>not</strong> time reversible in general (because the routing matrix <span class="math inline">\(P_{ij}\)</span> may not be symmetric), but the <strong>stationary distribution</strong> still exists and has a nice form.</p>
<hr>
</section>
<section id="summary-time-reversibility" class="level3">
<h3 class="anchored" data-anchor-id="summary-time-reversibility">Summary: Time Reversibility</h3>
<ul>
<li>A continuous-time Markov chain is <strong>time reversible</strong> if: <span class="math display">\[
P_i q_{ij} = P_j q_{ji}, \quad \text{for all } i, j
\]</span></li>
<li>Time-reversible chains have a particularly simple form of the <strong>balance equations</strong></li>
<li>Common reversible examples:
<ul>
<li>Birth‚Äìdeath processes</li>
<li>M/M/s queues</li>
<li>Some queueing networks with symmetric routing</li>
</ul></li>
</ul>
</section>
</section>
<section id="applications-of-continuous-time-markov-chains" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-continuous-time-markov-chains">6.7 Applications of Continuous-Time Markov Chains</h2>
<p>We now consider some practical applications of the theory of continuous-time Markov chains.</p>
<hr>
<section id="example-6.20-switching-between-two-machines" class="level3">
<h3 class="anchored" data-anchor-id="example-6.20-switching-between-two-machines">Example 6.20 (Switching Between Two Machines)</h3>
<p>A factory has two machines, A and B. Only one is operated at a time. When A is operating, it breaks down at rate <span class="math inline">\(\lambda_1\)</span>, and when B is operating, it breaks down at rate <span class="math inline">\(\lambda_2\)</span>. When a machine breaks, the other is repaired and operation switches to that one. The time to repair is negligible.</p>
<p><strong>State description</strong>:<br>
Let the state be the currently running machine: state 1 = A, state 2 = B.</p>
<p><strong>Transition rates</strong>: - From state 1 to 2: <span class="math inline">\(\lambda_1\)</span> - From state 2 to 1: <span class="math inline">\(\lambda_2\)</span></p>
<p>This forms a two-state continuous-time Markov chain.</p>
<p><strong>Limiting probabilities</strong>: - Let <span class="math inline">\(P_1\)</span> and <span class="math inline">\(P_2\)</span> be the steady-state probabilities.</p>
<p>From balance: <span class="math display">\[
\lambda_1 P_1 = \lambda_2 P_2
\]</span></p>
<p>With <span class="math inline">\(P_1 + P_2 = 1\)</span>: <span class="math display">\[
P_1 = \frac{\lambda_2}{\lambda_1 + \lambda_2}, \quad P_2 = \frac{\lambda_1}{\lambda_1 + \lambda_2}
\]</span></p>
<p>So the <strong>long-run proportion of time</strong> that machine A is operating is <span class="math inline">\(P_1\)</span>.</p>
<hr>
</section>
<section id="example-6.21-system-availability" class="level3">
<h3 class="anchored" data-anchor-id="example-6.21-system-availability">Example 6.21 (System Availability)</h3>
<p>A two-unit system operates as long as <strong>at least one unit is operational</strong>.<br>
Each unit: - fails with rate <span class="math inline">\(\lambda\)</span> - is repaired with rate <span class="math inline">\(\mu\)</span></p>
<p>If both are operational, the failure of either results in a transition to one unit working. If only one is working and it fails, system is down.</p>
<p><strong>States</strong>: - 2: both working<br>
- 1: one working<br>
- 0: both failed</p>
<p><strong>Transitions</strong>: - <span class="math inline">\(2 \to 1\)</span> with rate <span class="math inline">\(2\lambda\)</span> - <span class="math inline">\(1 \to 0\)</span> with rate <span class="math inline">\(\lambda\)</span> - <span class="math inline">\(1 \to 2\)</span> with rate <span class="math inline">\(\mu\)</span> - <span class="math inline">\(0 \to 1\)</span> with rate <span class="math inline">\(\mu\)</span></p>
<p><strong>Balance equations</strong>: Let <span class="math inline">\(P_0\)</span>, <span class="math inline">\(P_1\)</span>, <span class="math inline">\(P_2\)</span> be steady-state probabilities.</p>
<p>From flow balance: - <span class="math inline">\(\lambda P_1 = \mu P_0\)</span> - <span class="math inline">\(2\lambda P_2 = \mu P_1\)</span> - <span class="math inline">\(P_0 + P_1 + P_2 = 1\)</span></p>
<p>Solve: 1. <span class="math inline">\(P_0 = \frac{\lambda}{\mu} P_1\)</span> 2. <span class="math inline">\(P_2 = \frac{\mu}{2\lambda} P_1\)</span></p>
<p>Substitute into normalization: <span class="math display">\[
\frac{\lambda}{\mu} P_1 + P_1 + \frac{\mu}{2\lambda} P_1 = 1 \Rightarrow P_1 \left( \frac{\lambda}{\mu} + 1 + \frac{\mu}{2\lambda} \right) = 1
\]</span></p>
<p>Solve for <span class="math inline">\(P_1\)</span>, then: <span class="math display">\[
P_{\text{up}} = P_1 + P_2 = 1 - P_0
\]</span></p>
<p>This gives <strong>long-run availability</strong> of the system.</p>
<hr>
</section>
<section id="example-6.22-computer-virus-spread" class="level3">
<h3 class="anchored" data-anchor-id="example-6.22-computer-virus-spread">Example 6.22 (Computer Virus Spread)</h3>
<p>A network of <span class="math inline">\(n\)</span> computers. Any infected computer can infect any uninfected one at rate <span class="math inline">\(\lambda\)</span>, and any infected computer gets cleaned at rate <span class="math inline">\(\mu\)</span>.</p>
<p>Let <span class="math inline">\(X(t)\)</span> be the number of infected computers at time <span class="math inline">\(t\)</span>. Then <span class="math inline">\(\{X(t)\}\)</span> is a <strong>birth‚Äìdeath process</strong> on states <span class="math inline">\(0\)</span> to <span class="math inline">\(n\)</span>, with:</p>
<ul>
<li><span class="math inline">\(\lambda_i = \lambda i (n - i)\)</span>: <span class="math inline">\(i\)</span> infected can infect <span class="math inline">\((n - i)\)</span> others</li>
<li><span class="math inline">\(\mu_i = \mu i\)</span>: each infected gets cleaned</li>
</ul>
<p><strong>Goal</strong>: find the <strong>expected time to infection extinction</strong> starting from <span class="math inline">\(i\)</span> infected computers.</p>
<p>Let <span class="math inline">\(m_i = \mathbb{E}[\text{time until absorption at 0} \mid X(0) = i]\)</span></p>
<p>Recursion: <span class="math display">\[
m_0 = 0 \\
m_i = \frac{1}{\lambda_i + \mu_i} + \frac{\lambda_i}{\lambda_i + \mu_i} m_{i+1} + \frac{\mu_i}{\lambda_i + \mu_i} m_{i-1}, \quad i = 1, \dots, n-1 \\
m_n = \frac{1}{\mu_n} + m_{n-1}
\]</span></p>
<p>This is a standard way to compute <strong>expected hitting times</strong> in birth‚Äìdeath processes.</p>
<hr>
</section>
<section id="application-notes" class="level3">
<h3 class="anchored" data-anchor-id="application-notes">Application Notes</h3>
<p>The above examples illustrate: - Modeling with CTMCs by carefully defining <strong>states</strong> and <strong>transition rates</strong> - Using <strong>limiting probabilities</strong> for long-run behavior - Using <strong>first-step analysis</strong> and recurrence relations to solve for expectations - Relevance to systems reliability, networking, queueing, and more</p>
</section>
</section>
<section id="applications-of-continuous-time-markov-chains-1" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-continuous-time-markov-chains-1">6.7 Applications of Continuous-Time Markov Chains</h2>
<p>We now consider some practical applications of the theory of continuous-time Markov chains.</p>
<hr>
<section id="example-6.20-switching-between-two-machines-1" class="level3">
<h3 class="anchored" data-anchor-id="example-6.20-switching-between-two-machines-1">Example 6.20 (Switching Between Two Machines)</h3>
<p>A factory has two machines, A and B. Only one is operated at a time. When A is operating, it breaks down at rate <span class="math inline">\(\lambda_1\)</span>, and when B is operating, it breaks down at rate <span class="math inline">\(\lambda_2\)</span>. When a machine breaks, the other is repaired and operation switches to that one. The time to repair is negligible.</p>
<p><strong>State description</strong>:<br>
Let the state be the currently running machine: state 1 = A, state 2 = B.</p>
<p><strong>Transition rates</strong>: - From state 1 to 2: <span class="math inline">\(\lambda_1\)</span> - From state 2 to 1: <span class="math inline">\(\lambda_2\)</span></p>
<p>This forms a two-state continuous-time Markov chain.</p>
<p><strong>Limiting probabilities</strong>: - Let <span class="math inline">\(P_1\)</span> and <span class="math inline">\(P_2\)</span> be the steady-state probabilities.</p>
<p>From balance: <span class="math display">\[
\lambda_1 P_1 = \lambda_2 P_2
\]</span></p>
<p>With <span class="math inline">\(P_1 + P_2 = 1\)</span>: <span class="math display">\[
P_1 = \frac{\lambda_2}{\lambda_1 + \lambda_2}, \quad P_2 = \frac{\lambda_1}{\lambda_1 + \lambda_2}
\]</span></p>
<p>So the <strong>long-run proportion of time</strong> that machine A is operating is <span class="math inline">\(P_1\)</span>.</p>
<hr>
</section>
<section id="example-6.21-system-availability-1" class="level3">
<h3 class="anchored" data-anchor-id="example-6.21-system-availability-1">Example 6.21 (System Availability)</h3>
<p>A two-unit system operates as long as <strong>at least one unit is operational</strong>.<br>
Each unit: - fails with rate <span class="math inline">\(\lambda\)</span> - is repaired with rate <span class="math inline">\(\mu\)</span></p>
<p>If both are operational, the failure of either results in a transition to one unit working. If only one is working and it fails, system is down.</p>
<p><strong>States</strong>: - 2: both working<br>
- 1: one working<br>
- 0: both failed</p>
<p><strong>Transitions</strong>: - <span class="math inline">\(2 \to 1\)</span> with rate <span class="math inline">\(2\lambda\)</span> - <span class="math inline">\(1 \to 0\)</span> with rate <span class="math inline">\(\lambda\)</span> - <span class="math inline">\(1 \to 2\)</span> with rate <span class="math inline">\(\mu\)</span> - <span class="math inline">\(0 \to 1\)</span> with rate <span class="math inline">\(\mu\)</span></p>
<p><strong>Balance equations</strong>: Let <span class="math inline">\(P_0\)</span>, <span class="math inline">\(P_1\)</span>, <span class="math inline">\(P_2\)</span> be steady-state probabilities.</p>
<p>From flow balance: - <span class="math inline">\(\lambda P_1 = \mu P_0\)</span> - <span class="math inline">\(2\lambda P_2 = \mu P_1\)</span> - <span class="math inline">\(P_0 + P_1 + P_2 = 1\)</span></p>
<p>Solve: 1. <span class="math inline">\(P_0 = \frac{\lambda}{\mu} P_1\)</span> 2. <span class="math inline">\(P_2 = \frac{\mu}{2\lambda} P_1\)</span></p>
<p>Substitute into normalization: <span class="math display">\[
\frac{\lambda}{\mu} P_1 + P_1 + \frac{\mu}{2\lambda} P_1 = 1 \Rightarrow P_1 \left( \frac{\lambda}{\mu} + 1 + \frac{\mu}{2\lambda} \right) = 1
\]</span></p>
<p>Solve for <span class="math inline">\(P_1\)</span>, then: <span class="math display">\[
P_{\text{up}} = P_1 + P_2 = 1 - P_0
\]</span></p>
<p>This gives <strong>long-run availability</strong> of the system.</p>
<hr>
</section>
<section id="example-6.22-computer-virus-spread-1" class="level3">
<h3 class="anchored" data-anchor-id="example-6.22-computer-virus-spread-1">Example 6.22 (Computer Virus Spread)</h3>
<p>A network of <span class="math inline">\(n\)</span> computers. Any infected computer can infect any uninfected one at rate <span class="math inline">\(\lambda\)</span>, and any infected computer gets cleaned at rate <span class="math inline">\(\mu\)</span>.</p>
<p>Let <span class="math inline">\(X(t)\)</span> be the number of infected computers at time <span class="math inline">\(t\)</span>. Then <span class="math inline">\(\{X(t)\}\)</span> is a <strong>birth‚Äìdeath process</strong> on states <span class="math inline">\(0\)</span> to <span class="math inline">\(n\)</span>, with:</p>
<ul>
<li><span class="math inline">\(\lambda_i = \lambda i (n - i)\)</span>: <span class="math inline">\(i\)</span> infected can infect <span class="math inline">\((n - i)\)</span> others</li>
<li><span class="math inline">\(\mu_i = \mu i\)</span>: each infected gets cleaned</li>
</ul>
<p><strong>Goal</strong>: find the <strong>expected time to infection extinction</strong> starting from <span class="math inline">\(i\)</span> infected computers.</p>
<p>Let <span class="math inline">\(m_i = \mathbb{E}[\text{time until absorption at 0} \mid X(0) = i]\)</span></p>
<p>Recursion: <span class="math display">\[
m_0 = 0 \\
m_i = \frac{1}{\lambda_i + \mu_i} + \frac{\lambda_i}{\lambda_i + \mu_i} m_{i+1} + \frac{\mu_i}{\lambda_i + \mu_i} m_{i-1}, \quad i = 1, \dots, n-1 \\
m_n = \frac{1}{\mu_n} + m_{n-1}
\]</span></p>
<p>This is a standard way to compute <strong>expected hitting times</strong> in birth‚Äìdeath processes.</p>
<hr>
</section>
<section id="application-notes-1" class="level3">
<h3 class="anchored" data-anchor-id="application-notes-1">Application Notes</h3>
<p>The above examples illustrate:</p>
<ul>
<li>Modeling with CTMCs by carefully defining <strong>states</strong> and <strong>transition rates</strong></li>
<li>Using <strong>limiting probabilities</strong> for long-run behavior</li>
<li>Using <strong>first-step analysis</strong> and recurrence relations to solve for expectations</li>
<li>Relevance to systems reliability, networking, queueing, and more</li>
</ul>
</section>
</section>
</div>
</div>
</div>
<section id="fungsi-probabilitas-transisi" class="level2">
<h2 class="anchored" data-anchor-id="fungsi-probabilitas-transisi">6.4 Fungsi Probabilitas Transisi</h2>
<p>Misalkan <span class="math display">\[P_{ij}(t) = \mathbb{P}\{X(t + s) = j \mid X(s) = i\}\]</span> denotasikan probabilitas bahwa <strong>proses</strong> ada di keadaan <span class="math inline">\(i\)</span> akan berada di keadaan <span class="math inline">\(j\)</span> setelah <span class="math inline">\(t\)</span> waktu. Kuantitas ini yang sering disebut probabilitas transisi dari rantai markov waktu kontinu.</p>
<p>Kita dapat secara eksplisit menentukan <span class="math inline">\(P_{ij}(t)\)</span> dalam proses kasus kelahiran murni yang memiliki rate kelahiran <em>distinct</em>. Untuk sebuah proses, misal <span class="math inline">\(X_k\)</span> dinotasikan lama waktu <strong>proses</strong> menghabiskan di keadaan <span class="math inline">\(k\)</span> sebelum berpindah ke keadaan <span class="math inline">\(k+1\)</span>, <span class="math inline">\(k \geq 1\)</span>. Asumsikan <strong>proses</strong> ada di keadaan <span class="math inline">\(i\)</span> dan misalkan <span class="math inline">\(j&gt; i\)</span>. Maka, ketika <span class="math inline">\(X_i\)</span> adalah lama waktu yang dihabiskan di keadaan <span class="math inline">\(i\)</span> sebelum bergerak ke keadaan <span class="math inline">\(i+1\)</span>, dan <span class="math inline">\(X_{i+1}\)</span> adalah lama waktu yang dihabiskan di keadaan <span class="math inline">\(i+1\)</span> sebelum bergerak ke keadaan <span class="math inline">\(i+2\)</span>, dan seterusnya, mengikuti <span class="math display">\[\sum_{k=i}^{j-1} X_k = X_i + X_{i+1} + X_{i+2} + \cdots + X_{j-1}\]</span> adalah lama waktu yang dibutuhkan sebelum <strong>proses</strong> masuk ke keadaan <span class="math inline">\(j\)</span>. Sekarang, jika <strong>proses</strong> belum masuk ke keadaan <span class="math inline">\(j\)</span> pada waktu <span class="math inline">\(t\)</span>, maka itu sama aja bilang keadaan <span class="math inline">\(t\)</span> lebih kecil dari <span class="math inline">\(j\)</span>, dan sebaliknya. Atau kalo secara matematis ditulisnya. <span class="math display">\[X(t)&lt;j \iff X_i + \cdots + X_{j-1} &gt; t\]</span> Oleh karenanya, untuk <span class="math inline">\(i&lt;j\)</span> proses kelahiran murni, kita punya <span class="math display">\[
\begin{aligned}
\mathbb{P}\{X(t) &lt; j \mid X(0) = i\} &amp;= \mathbb{P}\left\{ \sum_{k=i}^{j-1} X_k &gt; t \right\} \\
&amp;= \mathbb{P}\left\{ X_i + X_{i+1} + X_{i+2} + \cdots + X_{j-1} &gt; t\right\}
\end{aligned}
\]</span></p>
<p>Akan tetapi, sebab <span class="math inline">\(X_i, \ldots,X_{j-1}\)</span> adalah variabel acak eksponensial dengan masing-masing ratesnya <span class="math inline">\(\lambda_i, \ldots, \lambda_{j-1}\)</span>, kita dapat peroleh dari <strong>Konvolusi Variabel Acak Eksponensial</strong> yang mana fungsi distribusi ekor dari <span class="math inline">\(\sum_{k=i}^{j-1} X_k\)</span>, itu <span class="math display">\[
\mathbb{P}\{X(t) &lt; j \mid X(0) = i\} = \sum_{k=i}^{j-1} e^{-\lambda_k t} \prod_{\substack{r=i \\ r \ne k}}^{j-1} \frac{\lambda_r}{\lambda_r - \lambda_k}
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled" title="kalo lu lupa fungsi distribusi ekor dari konvolusi eksponensial">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
kalo lu lupa fungsi distribusi ekor dari konvolusi eksponensial
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<section id="konvolusi-dari-variabel-acak-eksponensial" class="level3 callout-body-container callout-body">
<h3 class="anchored" data-anchor-id="konvolusi-dari-variabel-acak-eksponensial">5.2.4 Konvolusi dari variabel acak eksponensial</h3>
<p>Misal <span class="math inline">\(X_i, i = 1, \ldots, n\)</span>, adalah variabel acak eksponensial independen dengan rates masing-masing <span class="math inline">\(\lambda_i, i = 1, \ldots , n\)</span> dan asumsikan <span class="math inline">\(\lambda_i \neq \lambda_j\)</span> untuk <span class="math inline">\(i \neq j\)</span>. Variabel acak <span class="math inline">\(\sum_{i=1}^n X_i\)</span> dikatakan variabel acak <em>hypoeksponensial</em>.</p>
<p>Untuk hitung fungsi padatan probabilitas, pertama mulai pada kasus <span class="math inline">\(n=2\)</span>. Sekarang,</p>
<p><span class="math display">\[
\begin{aligned}
f_{X_1+X_2} &amp;= \int_0^t f_{X_1}(s) f_{X_2}(t-s)ds \\
&amp;= \int_0^t \lambda_1e^{-\lambda_1s}\lambda_2e^{-\lambda_2(t-s)} ds \\
&amp;= \lambda_1 \lambda_2 e^{-\lambda_2t} \int_0^t e^{-(\lambda_1 - \lambda_2)s} ds \\
&amp;= \frac{\lambda_1}{\lambda_1 -\lambda_2} \lambda_2 e^{-\lambda_2t}(1-e^{-(\lambda_1 - \lambda_2)t}) \\
&amp;= \frac{\lambda_1}{\lambda_1 - \lambda_2} \lambda_2 e^{-\lambda_2 t} + \frac{\lambda_2}{\lambda_2 - \lambda_1} \lambda_1 e^{-\lambda_1t}
\end{aligned}
\]</span></p>
<p>dengan cara yang sama untuk <span class="math inline">\(n=3\)</span>, yakni</p>
<p><span class="math display">\[
\begin{aligned}
f_{X_1+X_2+X_3} &amp;= \int_0^t f_{X_1 + X_2}(s)f_{X_3}(t-s)ds \\
&amp;= \int_0^t \left( \frac{\lambda_1}{\lambda_1 - \lambda_2} \lambda_2 e^{-\lambda_2 s} + \frac{\lambda_2}{\lambda_2 - \lambda_1} \lambda_1 e^{-\lambda_1s} \right) \lambda_3e^{-\lambda_3(t-s)} ds \\
&amp;= \int_0^t \left( \frac{\lambda_1}{\lambda_1 - \lambda_2} \lambda_2 e^{-\lambda_2 s} + \frac{\lambda_2}{\lambda_2 - \lambda_1} \lambda_1 e^{-\lambda_1s} \right) \lambda_3e^{\lambda_3s} e^{-\lambda_3t} ds \\
&amp;= \int_0^t \left( \frac{\lambda_1}{\lambda_1 - \lambda_2} \lambda_2 \lambda_3 e^{-(\lambda_2 - \lambda_3)s} + \frac{\lambda_2}{\lambda_2 - \lambda_1} \lambda_1 \lambda_3 e^{-(\lambda_1-\lambda_3)s} \right)e^{-\lambda_3t} ds \\
&amp;= e^{-\lambda_3t} \left(\int_0^t \frac{\lambda_1}{\lambda_1 - \lambda_2} \lambda_2 \lambda_3 e^{-(\lambda_2 - \lambda_3)s} ds + \int_0^t \frac{\lambda_2}{\lambda_2 - \lambda_1} \lambda_1 \lambda_3 e^{-(\lambda_1-\lambda_3)s} ds \right)\\
&amp;= e^{-\lambda_3t} \left(
    \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   \int_0^t e^{-(\lambda_2 - \lambda_3)s} ds +
    \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}  \int_0^t e^{-(\lambda_1-\lambda_3)s} ds \right)\\
&amp;= e^{-\lambda_3t} \left(
    \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
    \frac{1}{\lambda_2 - \lambda_3} \left(
    1- e^{-(\lambda_2 - \lambda_3)t}
    \right) +
    \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
    \frac{1}{\lambda_1 - \lambda_3}\left(
     1 - e^{-(\lambda_1 - \lambda_3)t}
     \right)
    \right)\\
&amp;= \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
   \frac{e^{-\lambda_3t}}{\lambda_2 - \lambda_3} \left(
    1- e^{-(\lambda_2 - \lambda_3)t}
    \right) +
    \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
    \frac{e^{-\lambda_3t}}{\lambda_1 - \lambda_3}\left(
    1 - e^{-(\lambda_1 - \lambda_3)t}
    \right) \\
&amp;= \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}  
   \frac{e^{-\lambda_3t}}{\lambda_2 - \lambda_3} -
   \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
   \frac{e^{-\lambda_2t}}{\lambda_2 - \lambda_3} +
   \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
   \frac{e^{-\lambda_3t}}{\lambda_1 - \lambda_3} -
   \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
   \frac{e^{-\lambda_1t}}{\lambda_1 - \lambda_3} \\
   \\
&amp;= \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
   \frac{e^{-\lambda_3t}}{\lambda_2 - \lambda_3} -
   \underbrace{
   \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}  
   \frac{e^{-\lambda_2t}}{\lambda_2 - \lambda_3}
    }_{\text{ada }\lambda_2\text{ pembilang \&amp; penyebut}} +
   \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
   \frac{e^{-\lambda_3t}}{\lambda_1 - \lambda_3} -
   \underbrace{
   \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
   \frac{e^{-\lambda_1t}}{\lambda_1 - \lambda_3}
   }_{\text{ada }\lambda_1\text{ pembilang \&amp; penyebut}} \\
   \\
&amp;= \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
   \frac{e^{-\lambda_3t}}{\lambda_2 - \lambda_3} +
   \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
   \frac{e^{-\lambda_2t}}{\lambda_3 - \lambda_2} +
   \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
   \frac{e^{-\lambda_3t}}{\lambda_1 - \lambda_3} +
   \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
   \frac{e^{-\lambda_1t}}{\lambda_3 - \lambda_1} \\
&amp;= \underbrace{
   \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
   \frac{e^{-\lambda_3t}}{\lambda_2 - \lambda_3} +
   \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
   \frac{e^{-\lambda_3t}}{\lambda_1 - \lambda_3}
   }_{\text{kumpulan } \lambda_3} +
   \underbrace{
   \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
   \frac{e^{-\lambda_2t}}{\lambda_3 - \lambda_2}
    }_{\text{kumpulan } \lambda_2} +
   \underbrace{
   \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
   \frac{e^{-\lambda_1t}}{\lambda_3 - \lambda_1}
    }_{\text{kumpulan } \lambda_1} \\
\end{aligned}
\]</span></p>
<p>Oke, sekarang kita akan rapihin kumpulan <span class="math inline">\(\lambda_3\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\text{kumpulan } \lambda_3
&amp;=  \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
    \frac{e^{-\lambda_3t}}{\lambda_2 - \lambda_3} +
    \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_2 - \lambda_1}
    \frac{e^{-\lambda_3t}}{\lambda_1 - \lambda_3} \\
&amp;=  \lambda_1 \lambda_2 \lambda_3 e^{-\lambda_3t}
    \left(
        \frac{1}{(\lambda_1 - \lambda_2)(\lambda_2 - \lambda_3)} +
        \frac{1}{(\lambda_2 - \lambda_1)(\lambda_1 - \lambda_3)}
    \right) \\
&amp;=  \lambda_1 \lambda_2 \lambda_3 e^{-\lambda_3t}
    \left(
        \frac{1}{(\lambda_1 - \lambda_2)(\lambda_2 - \lambda_3)} -
        \frac{1}{(\lambda_1 - \lambda_2)(\lambda_1 - \lambda_3)}
    \right) \\
&amp;=  \lambda_1 \lambda_2 \lambda_3 e^{-\lambda_3t}
    \left(
        \left[\frac{1}{\lambda_1 - \lambda_2}\right]
        \frac{1}{\lambda_2 - \lambda_3} -
        \frac{1}{\lambda_1 - \lambda_3}
    \right) \\
&amp;=  \lambda_1 \lambda_2 \lambda_3 e^{-\lambda_3t}
    \left[\frac{1}{\lambda_1 - \lambda_2}\right]
    \frac{\lambda_1 - \lambda_3 - (\lambda_2 - \lambda_3)}{(\lambda_2 - \lambda_3)(\lambda_1 - \lambda_3)} \\
&amp;=  \lambda_1 \lambda_2 \lambda_3 e^{-\lambda_3t}
    \left[\frac{1}{\lambda_1 - \lambda_2}\right]
    \frac{\lambda_1 - \lambda_2}{(\lambda_2 - \lambda_3)(\lambda_1 - \lambda_3)}\\
&amp;=  \lambda_1 \lambda_2 \lambda_3 e^{-\lambda_3t}
    \frac{1}{(\lambda_2 - \lambda_3)(\lambda_1 - \lambda_3)} \\
&amp;=  \frac{\lambda_1 \lambda_2 \lambda_3 e^{-\lambda_3t}}
    {(\lambda_2 - \lambda_3)(\lambda_1 - \lambda_3)} \\
    \\
&amp;=  \frac{\lambda_1}{\lambda_1 - \lambda_3}
    \frac{\lambda_2}{\lambda_2 - \lambda_3}
    \lambda_3 e^{-\lambda_3t}\\
\end{aligned}
\]</span></p>
<p>lalu, untuk kumpulan <span class="math inline">\(\lambda_2\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\text{kumpulan } \lambda_2
&amp;=  \frac{\lambda_1 \lambda_2 \lambda_3}{\lambda_1 - \lambda_2}   
    \frac{e^{-\lambda_2t}}{\lambda_3 - \lambda_2}\\
&amp;=  \frac{\lambda_1}{\lambda_1 - \lambda_2}
    \frac{\lambda_3}{\lambda_3 - \lambda_2}
    \lambda_2 e^{-\lambda_2t}\\
\end{aligned}
\]</span></p>
<p>lalu, untuk kumpulan <span class="math inline">\(\lambda_1\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\text{kumpulan } \lambda_1
&amp;=  \frac{\lambda_2 \lambda_1 \lambda_3}{\lambda_2 - \lambda_1}
    \frac{e^{-\lambda_1t}}{\lambda_3 - \lambda_1}\\
&amp;=  \frac{\lambda_2}{\lambda_2 - \lambda_1}
    \frac{\lambda_3}{\lambda_3 - \lambda_1}
    \lambda_1 e^{-\lambda_1t}
\end{aligned}
\]</span></p>
<p>Jadi, mah intinya</p>
<p><span class="math display">\[
\begin{aligned}
f_{X_1+X_2+X_3}
&amp;= \frac{\lambda_1}{\lambda_1 - \lambda_3} \frac{\lambda_2}{\lambda_2 - \lambda_3} \lambda_3 e^{-\lambda_3t}\\
&amp;+ \frac{\lambda_1}{\lambda_1 - \lambda_2} \frac{\lambda_3}{\lambda_3 - \lambda_2} \lambda_2 e^{-\lambda_2t}\\
&amp;+ \frac{\lambda_2}{\lambda_2 - \lambda_1}\frac{\lambda_3}{\lambda_3 - \lambda_1} \lambda_1 e^{-\lambda_1t}
\end{aligned}
\]</span></p>
<p>atau</p>
<p><span class="math display">\[
f_{X_1+X_2+X_3} = \sum_{k=1}^{3} e^{-\lambda_k t} \prod_{\substack{r=1 \\ r \ne k}}^{3} \frac{\lambda_r}{\lambda_r - \lambda_k}
\]</span></p>
<p>ini ada buktinya pakai induksi matematika, tapi gw nggak akan ngebuktiin disini. Intinya lu tau kalo proses stokastik ini pakai <em>convolution hypoexponential</em>.</p>
</section>
</div>
</div>
<p>Ganti <span class="math inline">\(j\)</span> dengan <span class="math inline">\(j+1\)</span> diperoleh</p>
<p><span class="math display">\[
\mathbb{P}\{X(t) &lt; j+1 \mid X(0) = i\} = \sum_{k=i}^{j} e^{-\lambda_k t} \prod_{\substack{r=i \\ r \ne k}}^{j} \frac{\lambda_r}{\lambda_r - \lambda_k}
\]</span></p>
<p>Ingat lagi, karena parameter waktunya kontinu. Tapi ruang keadaannya tetap <strong>diskrit</strong>. Maka,</p>
<p><span class="math display">\[
\mathbb{P}\{X=x\}=\mathbb{P}\{X&lt;x+1\} - \mathbb{P}\{X&lt;x\}
\]</span></p>
<p>yakni <span class="math display">\[
\begin{split}
\mathbb{P}\{X(t) = j \mid X(0) = i\} = \mathbb{P}\{X(t) &lt; j+1 \mid X(0) = i\} \\
- \mathbb{P}\{X(t) &lt; j \mid X(0) = i\}
\end{split}
\]</span></p>
<p>dan karena <span class="math inline">\(P_{ii}(t) = \mathbb{P}\{X_i &gt; t\} = e^{-\lambda_i t}\)</span>. Maka, sifat ini mengikuti.</p>
<section id="proposition-6.1-1" class="level3">
<h3 class="anchored" data-anchor-id="proposition-6.1-1">Proposition 6.1</h3>
<p>Untuk <strong>proses</strong> kelahiran murni yang memiliki <span class="math inline">\(\lambda_i \ne \lambda_j\)</span> ketika <span class="math inline">\(i \ne j\)</span>:</p>
<p><span class="math display">\[
P_{ij}(t) = \sum_{k=i}^{j} e^{-\lambda_k t} \prod_{\substack{r=i \\ r \ne k}}^{j} \frac{\lambda_r}{\lambda_r - \lambda_k} - \sum_{k=i}^{j-1} e^{-\lambda_k t} \prod_{\substack{r=i \\ r \ne k}}^{j-1} \frac{\lambda_r}{\lambda_r - \lambda_k}, \quad i &lt; j
\]</span></p>
<p><span class="math display">\[
P_{ii}(t) = e^{-\lambda_i t}
\]</span></p>
</section>
<section id="contoh-6.8" class="level3">
<h3 class="anchored" data-anchor-id="contoh-6.8">Contoh 6.8</h3>
<p>Ingat lagi <strong>proses Yule</strong> dimana proses kelahiran murni yang masing-masing individu di populasi itu independen yang memberikan rate kelahiran <span class="math inline">\(\lambda\)</span>, dan begitu juga untuk <span class="math inline">\(\lambda_n = n\lambda, n \geq 1\)</span>. Misalkan <span class="math inline">\(i=1\)</span>, kita peroleh dari proposisi 6.1:</p>
<p><span class="math display">\[
P_{1j}(t) = \sum_{k=1}^{j} e^{-k\lambda t} \prod_{\substack{r=1 \\ r \ne k}}^{j} \frac{r}{r - k} - \sum_{k=1}^{j-1} e^{-k\lambda t} \prod_{\substack{r=1 \\ r \ne k}}^{j-1} \frac{r}{r - k}
\]</span></p>
<p>Ini disederhanakan menjadi: <span class="math display">\[
P_{1j}(t) = e^{-j\lambda t} \prod_{r=1}^{j-1} \frac{r}{r - j} + \sum_{k=1}^{j-1} e^{-k\lambda t} \left( \prod_{\substack{r=1 \\ r \ne k}}^{j} \frac{r}{r - k} - \prod_{\substack{r=1 \\ r \ne k}}^{j-1} \frac{r}{r - k} \right)
\]</span></p>
<p>Lebih lanjut kita dapat sederhanakan menjadi: <span class="math display">\[
\frac{k}{j-k} \prod_{\substack{r=1 \\ r \ne k}}^{j-1} \frac{r}{r - k} = \frac{(j-1)!}{(1-k)(2-k)\cdots(k-1-k)(j-k)!} = (-1)^{k-1} \binom{j-1}{k-1}
\]</span></p>
<p>Sehingga: <span class="math display">\[
P_{1j}(t) = \sum_{k=1}^{j} \binom{j-1}{k-1} e^{-k\lambda t} (-1)^{k-1}
\]</span></p>
<p>Misalkan <span class="math inline">\(i = j-k\)</span>, dan menyederhanakan index menjadi: <span class="math display">\[
P_{1j}(t) = e^{-\lambda t} \sum_{i=0}^{j-1} \binom{j-1}{i} e^{-i\lambda t} (-1)^i = e^{-\lambda t} (1 - e^{-\lambda t})^{j-1}
\]</span></p>
<p>Oleh karenanya, dimulai dari individu tunggal, ukuran populasi dimulai dari waktu <span class="math inline">\(t\)</span> memiliki <strong>distribusi geometrik</strong> dengan rerata <span class="math inline">\(e^{\lambdat}\)</span>. Jika populasi dimulai dari individu <span class="math inline">\(i\)</span>, kita dapat pertimbangkan masing-masing individu dimulai dari <strong>proses Yule independen</strong> sendiri, dan begitu populasi pada waktu <span class="math inline">\(t\)</span> akan dijumlahkan dari independen <span class="math inline">\(i\)</span> dan variabel acak distribusi geometrik identik dengan parameter $e^{-}.</p>
<p>Sehingga, ukuran populasi di waktu <span class="math inline">\(t\)</span> memiliki <strong>distribusi binomial negatif</strong> dengan parameter <span class="math inline">\(i\)</span> dan <span class="math inline">\(e^{\lambdat}\)</span>, jadi:</p>
<p><span class="math display">\[
P_{ij}(t) = \binom{j-1}{i-1} e^{-i\lambda t} (1 - e^{-\lambda t})^{j-i}, \quad j \ge i \ge 1
\]</span></p>
</section>
<section id="contoh-6.9" class="level3">
<h3 class="anchored" data-anchor-id="contoh-6.9">Contoh 6.9</h3>
<p>Sebuah gentong mengandung satu bola tipe 1 dan satu bola tipe 2.</p>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>